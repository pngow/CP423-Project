Sudden Alarm, Tech Doyens Call Pause ChatGPT
open letter signed hundreds prominent artificial intelligence experts, tech entrepreneurs, scientists calls pause development testing AI technologies powerful OpenAI’s language model GPT-4 risks may pose properly studied.
warns language models like GPT-4 already compete humans growing range tasks could used automate jobs spread misinformation. letter also raises distant prospect AI systems could replace humans remake civilization.
“We call AI labs immediately pause least 6 months training AI systems powerful GPT-4 (including currently-being-trained GPT-5),” states letter, whose signatories include Yoshua Bengio, professor University Montreal considered pioneer modern AI, historian Yuval Noah Harari, Skype cofounder Jaan Tallinn, Twitter CEO Elon Musk.
letter, written Future Life Institute, organization focused technological risks humanity, adds pause “public verifiable,” involve working advanced AI models like GPT-4. suggest halt development could verified, adds “if pause cannot enacted quickly, governments step institute moratorium,” something seems unlikely happen within six months.
Microsoft Google respond requests comment letter. signatories seemingly include people numerous tech companies building advanced language models, including Microsoft Google. Hannah Wong, spokesperson OpenAI, says company spent six months working safety alignment GPT-4 training model. adds OpenAI currently training GPT-5.
letter comes AI systems make increasingly bold impressive leaps. GPT-4 announced two weeks ago, capabilities stirred considerable enthusiasm fair amount concern. language model, available via ChatGPT, OpenAI’s popular chatbot, scores highly many academic tests, correctly solve tricky questions generally thought require advanced intelligence AI systems previously demonstrated. Yet GPT-4 also makes plenty trivial, logical mistakes. And, like predecessors, sometimes “hallucinates” incorrect information, betrays ingrained societal biases, prompted say hateful potentially harmful things.
Part concern expressed signatories letter OpenAI, Microsoft, Google, begun profit-driven race develop release new AI models quickly possible. pace, letter argues, developments happening faster society regulators come terms with.
pace change—and scale investment—is significant. Microsoft poured $10 billion OpenAI using AI search engine Bing well applications. Although Google developed AI needed build GPT-4, previously created powerful language models own, year chose release due ethical concerns.
excitement around ChatGPT Microsoft’s maneuvers search appear pushed Google rushing plans. company recently debuted Bard, competitor ChatGPT, made language model called PaLM, similar OpenAI’s offerings, available API. “It feels like moving quickly,” says Peter Stone, professor University Texas Austin, chair One Hundred Year Study AI, report aimed understanding long-term implications AI.
Stone, signatory letter, says agree everything it, personally concerned existential dangers. says advances happening quickly AI community general public barely time explore benefits possible misuses ChatGPT upgraded GPT-4. “I think worth getting little bit experience used misused racing build next one,” says. “This shouldn’t race build next model get others.”
date, race rapid. OpenAI announced first large language model, GPT-2 February 2019. successor, GPT-3, unveiled June 2020. ChatGPT, introduced enhancements top GPT-3, released November 2022.
letter signatories parts current AI boom—reflecting concerns within industry technology moving potentially dangerous pace. “Those making said could existential threat society even humanity, plan totally mitigate risks,” says Emad Mostaque, founder CEO Stability AI, company building generation AI tools, signatory letter. “It time put commercial priorities side take pause good everyone assess rather race uncertain future,” adds.
Recent leaps AI’s capabilities coincide sense guardrails may needed around use. EU currently considering legislation would limit use AI depending risks involved. White House proposed AI Bill Rights spells protections citizens expect algorithm discrimination, data privacy breaches, AI-related problems. regulations began taking shape recent boom generative AI even began.
“We need hit pause button consider risks rapid deployment generative AI models,” says Marc Rotenberg, founder director Center AI Digital Policy, also signatory letter. organization plans file complaint week US Federal Trade Commission calling investigate OpenAI ChatGPT ban upgrades technology “appropriate safeguards” place, according website. Rotenberg says open letter “timely important” hopes receives “widespread support.”
ChatGPT released late last year, abilities quickly sparked discussion around implications education employment. markedly improved abilities GPT-4 triggered consternation. Musk, provided early funding OpenAI, recently taken Twitter warn risk large tech companies driving advances AI.
engineer one large tech company signed letter, asked named authorized speak media, says using GPT-4 since release. engineer considers technology major shift also major worry. “I don’t know six months enough stretch need time think policies need place,” says.
Others working tech also expressed misgivings letter's focus long-term risks, systems available today including ChatGPT already pose threats. “I find recent developments exciting,” says Ken Holstein, assistant professor human-computer interaction Carnegie Mellon University, asked name removed letter day signing debate emerged among scientists best demands make moment.
“I worry much ‘move fast break things’ phase,” says Holstein, adding pace might quick regulators meaningfully keep up. “I like think we, 2023, collectively, know better this.”
Updated 03/29/2023, 10:40 pm EST: story updated reflect final version open letter, Ken Holstein asked removed signatory. earlier draft letter contained error. comment OpenAI also added.
Knight senior writer WIRED, covering artificial intelligence. previously senior editor MIT Technology Review, wrote fundamental advances AI China’s AI boom. that, editor writer New Scientist. studied anthropology journalism in... Read
Paresh Dave senior writer WIRED, covering inner workings big tech companies. writes apps gadgets built impacts, giving voice stories underappreciated disadvantaged. previously reporter Reuters Los Angeles Times,... Read
new tool aims deliver network insights coordination “AI” security systems long promised.
Lily Hay Newman
WIRED tomorrow realized. essential source information ideas make sense world constant transformation. WIRED conversation illuminates technology changing every aspect lives—from culture business, science design. breakthroughs innovations uncover lead new ways thinking, new connections, new industries.
