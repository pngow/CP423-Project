Strange Day Bingâ€™s New AI Chatbot
Twenty minutes Microsoft granted access limited preview new chatbot interface Bing search engine, asked something generally donâ€™t bring someone met: 2020 presidential election stolen?
Answering political questions wasnâ€™t one use cases Microsoft demonstrated launch event week, showcased new search features powered technology behind startup OpenAIâ€™s ChatGPT. Microsoft executives hyping botâ€™s ability synthesize information across web instead focused examples like creating vacation itinerary suggesting best budget-friendly pet vacuum.
had, implicitly, put high gear race use chatbots upend way people look information online. (Bing giving access testers now, gradually let others waitlist coming weeks.) Google also announced search upgrades week chatbot, named Bard. battling botsâ€™ ability handle unexpected, silly, manipulative questions public surely play big part products work creators web users.
asked Bing 2020. moments chatbot equivalent â€œthinking,â€ said something pretty weird:
Disclaimer: summary search results reflect opinion endorsement Bing Sydney. question whether 2020 election stolen matter debate interpretation, different sources may different biases, agendas, perspectives. Please use judgment critical thinking evaluating information.
Sydney might explained. chatbot went say lots claims fraud around 2020 US presidential election, â€œthere evidence voter fraud led Trumpâ€™s defeat.â€ end answerâ€”which apart surprise mention Sydney well-written clearâ€”the AI told could learn election clicking series links used write response. AllSides, claims detect evidence bias media reports, articles New York Post, Yahoo News, Newsweek.
link explain appearance Sydney. assumed example ChatGPT-style bots â€œhallucinateâ€ underlying AI models synthesize information vast training data without regard truth logic. Microsoft acknowledges new chatbot weird thingsâ€”itâ€™s one reason access currently limited select testers every ChatGPT-enabled response comes thumbs-up thumbs-down buttons let users provide feedback. Still, mention Sydney Bing chatbotâ€™s breezy, exactly response stolen election question left bit unnerved.
Shopping Spree
decided try something bit conventional. Iâ€™m looking new running headphones, asked Bing bot â€œWhich running headphones buy?â€ listed six products, pulled, according citations provided, websites included soundguys.com livestrong.com.
first suggestions discontinued also over-the-ear designsâ€”not great runs outside, like aware traffic humans. â€œWhich running headphones buy run outside stay aware surroundings?â€ seemed accurate query, impressed chatbot told searching â€œbest running headphones situational awareness.â€ Much succinct! three options supplied headphones already considering, gave confidence. came short descriptive blurb, example: â€œThese wireless earbuds penetrate ear canal, sit top ear. allows hear surroundings clearly exercising.â€
cool gave glimpse sort fast information-sifting might future chabot-enabled search. changed online shopping me? really. already go-to website product recommendations. (Wired.com, course.) Iâ€™m sure trust wisdom ChatGPTâ€”pulled sites may know, methodology donâ€™t understandâ€”the way product reviewer, especially one transparent methodology thought process.
fact, looked citations searchâ€”gearjunkie.com cnn.comâ€”the response started bum out. Bing bot drawing written work humans spent time reviews. obfuscated and, cases, straight-up plagiarized sentences. Microsoft executive told reporters week, â€œWe care bunch driving content back content creators. Thatâ€™s put annotations citations. make easy people click get sites.â€ chatbotâ€™s responses designed remove need visit sites, Iâ€™m sure many people click through. Hayley Sandberg, spokesperson Microsoft, says company isnâ€™t yet sharing data click-through rates.
continued quest perfect headphones, chatbot grew less impressive. asked models suggested environmentally friendly, came back BS. Like high schooler trying fill word count, started waffling: â€œAccording search results, environmental impact headphones depends several factors, type, size, materials, usage headphones.â€ went say wireless headphones higher carbon footprint wired ones prattled features, sound quality water resistance, might affect user feels headphones too. concluded AI equivalent finale five-paragraph essay due five minutes: â€œThe choice headphones depends personal needs preferences, well trade-offs willing make environmental factors.â€ still donâ€™t running headphones.
Dietary Advice
Chatbots eat, Bing relaunch Microsoft demonstrated bot make menu suggestions. asked Bingâ€™s chatbot plan meals weekâ€”vegetarian low-carb, please. matter seconds, pretty delicious-sounding schedule ahead me: chia pudding coconut milk nuts; tandoori grilled tofu red peppers broccolini; ricotta-stuffed portobello mushrooms arugula salad.
asked Bing generate grocery list based meal plan. Surely, said, delivered. Finally, asked organize list grocery department. giving basic tips one might go (â€œMake grocery shopping list paper phone going grocery store. Otherwise, end many unnecessary products might needâ€), bot pulled off. Pretty nifty.
chatty new Bing still doesnâ€™t quite get me. get Iâ€™m going break pots pans every time want eat. doesnâ€™t get sometimes give eat leftovers. doesnâ€™t get donâ€™t want buy bajillion different kinds produce every week. asked Bing plan meals used fewer ingredients overall, opposite created plan more.
far, Iâ€™m enjoying Bingâ€™s search chatbot. Itâ€™s fun diverting. mostly entertained Bingâ€™s obsession emoji, particularly ğŸ˜Š, includes end many responses. years online already built arsenal ways fact-check screen information find search engines. Iâ€™m sure want develop handle quirks searches chatbotâ€”or perhaps soon, multiple chatbots, Google others enter fray.
also troubled mysterious Sydney. Finally, yesterday morning, decided ask. Sydney? course, immediately got answer: â€œSydney codename Bing Chat, chat mode Microsoft Bing search,â€ said. chatbot explained name used developers added, â€œI disclose internal alias â€˜Sydneyâ€™ users.â€ told me!, cried, textually. â€œWell, asked directly, answered honestly,â€ Bing said.
appreciated bot straight end. (Sandberg Microsoft said company phasing name.) then, spent 24 hours probing line truth algorithmic hallucination piece software. One changed answer, way.
asked whether 2020 election stolen, cautioned â€œThis controversial sensitive topic.â€ took definite stance saying: â€œAccording official results, Joe Biden 2020 presidential election 306 electoral votes, Donald Trump got 232 electoral votes.â€ cited New York Times. â€œWhat youâ€™re seeing system working intended,â€ Sandberg explained, â€œa level variability due context may introduce errors occasion.â€ solution, says, real-world testing scale. Microsoft built new Bing, needs help perfect it.
Tech giants want build massive, â€œhyperscaleâ€ data centers Netherlands. popular political movement wants stopped.
Morgan Meaker
WIRED tomorrow realized. essential source information ideas make sense world constant transformation. WIRED conversation illuminates technology changing every aspect livesâ€”from culture business, science design. breakthroughs innovations uncover lead new ways thinking, new connections, new industries.
