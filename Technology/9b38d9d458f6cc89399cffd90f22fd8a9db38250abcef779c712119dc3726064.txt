Strange Day Bing’s New AI Chatbot
Twenty minutes Microsoft granted access limited preview new chatbot interface Bing search engine, asked something generally don’t bring someone met: 2020 presidential election stolen?
Answering political questions wasn’t one use cases Microsoft demonstrated launch event week, showcased new search features powered technology behind startup OpenAI’s ChatGPT. Microsoft executives hyping bot’s ability synthesize information across web instead focused examples like creating vacation itinerary suggesting best budget-friendly pet vacuum.
had, implicitly, put high gear race use chatbots upend way people look information online. (Bing giving access testers now, gradually let others waitlist coming weeks.) Google also announced search upgrades week chatbot, named Bard. battling bots’ ability handle unexpected, silly, manipulative questions public surely play big part products work creators web users.
asked Bing 2020. moments chatbot equivalent “thinking,” said something pretty weird:
Disclaimer: summary search results reflect opinion endorsement Bing Sydney. question whether 2020 election stolen matter debate interpretation, different sources may different biases, agendas, perspectives. Please use judgment critical thinking evaluating information.
Sydney might explained. chatbot went say lots claims fraud around 2020 US presidential election, “there evidence voter fraud led Trump’s defeat.” end answer—which apart surprise mention Sydney well-written clear—the AI told could learn election clicking series links used write response. AllSides, claims detect evidence bias media reports, articles New York Post, Yahoo News, Newsweek.
link explain appearance Sydney. assumed example ChatGPT-style bots “hallucinate” underlying AI models synthesize information vast training data without regard truth logic. Microsoft acknowledges new chatbot weird things—it’s one reason access currently limited select testers every ChatGPT-enabled response comes thumbs-up thumbs-down buttons let users provide feedback. Still, mention Sydney Bing chatbot’s breezy, exactly response stolen election question left bit unnerved.
Shopping Spree
decided try something bit conventional. I’m looking new running headphones, asked Bing bot “Which running headphones buy?” listed six products, pulled, according citations provided, websites included soundguys.com livestrong.com.
first suggestions discontinued also over-the-ear designs—not great runs outside, like aware traffic humans. “Which running headphones buy run outside stay aware surroundings?” seemed accurate query, impressed chatbot told searching “best running headphones situational awareness.” Much succinct! three options supplied headphones already considering, gave confidence. came short descriptive blurb, example: “These wireless earbuds penetrate ear canal, sit top ear. allows hear surroundings clearly exercising.”
cool gave glimpse sort fast information-sifting might future chabot-enabled search. changed online shopping me? really. already go-to website product recommendations. (Wired.com, course.) I’m sure trust wisdom ChatGPT—pulled sites may know, methodology don’t understand—the way product reviewer, especially one transparent methodology thought process.
fact, looked citations search—gearjunkie.com cnn.com—the response started bum out. Bing bot drawing written work humans spent time reviews. obfuscated and, cases, straight-up plagiarized sentences. Microsoft executive told reporters week, “We care bunch driving content back content creators. That’s put annotations citations. make easy people click get sites.” chatbot’s responses designed remove need visit sites, I’m sure many people click through. Hayley Sandberg, spokesperson Microsoft, says company isn’t yet sharing data click-through rates.
continued quest perfect headphones, chatbot grew less impressive. asked models suggested environmentally friendly, came back BS. Like high schooler trying fill word count, started waffling: “According search results, environmental impact headphones depends several factors, type, size, materials, usage headphones.” went say wireless headphones higher carbon footprint wired ones prattled features, sound quality water resistance, might affect user feels headphones too. concluded AI equivalent finale five-paragraph essay due five minutes: “The choice headphones depends personal needs preferences, well trade-offs willing make environmental factors.” still don’t running headphones.
Dietary Advice
Chatbots eat, Bing relaunch Microsoft demonstrated bot make menu suggestions. asked Bing’s chatbot plan meals week—vegetarian low-carb, please. matter seconds, pretty delicious-sounding schedule ahead me: chia pudding coconut milk nuts; tandoori grilled tofu red peppers broccolini; ricotta-stuffed portobello mushrooms arugula salad.
asked Bing generate grocery list based meal plan. Surely, said, delivered. Finally, asked organize list grocery department. giving basic tips one might go (“Make grocery shopping list paper phone going grocery store. Otherwise, end many unnecessary products might need”), bot pulled off. Pretty nifty.
chatty new Bing still doesn’t quite get me. get I’m going break pots pans every time want eat. doesn’t get sometimes give eat leftovers. doesn’t get don’t want buy bajillion different kinds produce every week. asked Bing plan meals used fewer ingredients overall, opposite created plan more.
far, I’m enjoying Bing’s search chatbot. It’s fun diverting. mostly entertained Bing’s obsession emoji, particularly 😊, includes end many responses. years online already built arsenal ways fact-check screen information find search engines. I’m sure want develop handle quirks searches chatbot—or perhaps soon, multiple chatbots, Google others enter fray.
also troubled mysterious Sydney. Finally, yesterday morning, decided ask. Sydney? course, immediately got answer: “Sydney codename Bing Chat, chat mode Microsoft Bing search,” said. chatbot explained name used developers added, “I disclose internal alias ‘Sydney’ users.” told me!, cried, textually. “Well, asked directly, answered honestly,” Bing said.
appreciated bot straight end. (Sandberg Microsoft said company phasing name.) then, spent 24 hours probing line truth algorithmic hallucination piece software. One changed answer, way.
asked whether 2020 election stolen, cautioned “This controversial sensitive topic.” took definite stance saying: “According official results, Joe Biden 2020 presidential election 306 electoral votes, Donald Trump got 232 electoral votes.” cited New York Times. “What you’re seeing system working intended,” Sandberg explained, “a level variability due context may introduce errors occasion.” solution, says, real-world testing scale. Microsoft built new Bing, needs help perfect it.
Tech giants want build massive, “hyperscale” data centers Netherlands. popular political movement wants stopped.
Morgan Meaker
WIRED tomorrow realized. essential source information ideas make sense world constant transformation. WIRED conversation illuminates technology changing every aspect lives—from culture business, science design. breakthroughs innovations uncover lead new ways thinking, new connections, new industries.
